{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a468561-bf3b-4816-8bc7-df9254bd527b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Monta o Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Caminho base do projeto\n",
    "base_path = \"/content/drive/MyDrive/Colab Notebooks/spark/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07e6aac1-5ec2-4a6a-8596-2c02c54e5bc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Carrega splits\n",
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "# Converte para pandas (usando apenas train e test)\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_test  = ds[\"test\"].to_pandas()\n",
    "\n",
    "# Mapeia label -> sentiment\n",
    "label_map = {0: \"negative\", 1: \"positive\"}\n",
    "df_train[\"sentiment\"] = df_train[\"label\"].map(label_map)\n",
    "df_test[\"sentiment\"]  = df_test[\"label\"].map(label_map)\n",
    "\n",
    "# Renomeia 'text' -> 'review' (para casar com o pipeline)\n",
    "df_train = df_train.rename(columns={\"text\": \"review\"})[[\"review\", \"sentiment\"]]\n",
    "df_test  = df_test.rename(columns={\"text\": \"review\"})[[\"review\", \"sentiment\"]]\n",
    "\n",
    "# Concatena os dois conjuntos\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Cria a pasta 'dados' no Drive se ainda n√£o existir\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Salva o CSV no Drive\n",
    "csv_path = os.path.join(base_path, \"dataset.csv\")\n",
    "df_all.to_csv(csv_path, index=False)\n",
    "\n",
    "print(df_all.head())\n",
    "print(f\"Dataset salvo em: {csv_path}\")\n",
    "print(f\"Total de linhas: {len(df_all)}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "coleta_dados",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
