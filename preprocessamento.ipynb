{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Ambiente (Java + PySpark + SparkSession)\n","# Fecha Spark anterior (se houver)\n","try:\n","    spark.stop()\n","except:\n","    pass\n","\n","# Java + PySpark estáveis para Python 3.12\n","!apt-get update -qq\n","!apt-get install -y openjdk-17-jdk-headless -qq\n","!pip -q install -U pyspark==3.5.1\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n","os.environ[\"PATH\"]  = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","\n","from pyspark.sql import SparkSession\n","spark = (SparkSession.builder\n","         .appName(\"eixo05-preprocess\")\n","         .getOrCreate())\n","print(\"Spark OK ->\", spark.version)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eG_u3j1684w","executionInfo":{"status":"ok","timestamp":1762080485817,"user_tz":0,"elapsed":15989,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"c3c3f89e-78da-4a93-d86a-4ee21520dade"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Spark OK -> 3.5.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ffbAi_I_dhhx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762080486737,"user_tz":0,"elapsed":916,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"b6f1d673-8134-4c5c-c8dc-1df795cc0812"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Base path: /content/drive/MyDrive/Eixo_05/dados/\n"]}],"source":["# Drive e caminhos\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","base_path = \"/content/drive/MyDrive/Eixo_05/dados/\"\n","csv_path  = base_path + \"dataset.csv\"\n","print(\"Base path:\", base_path)\n"]},{"cell_type":"code","source":["# Imports e helpers mínimos\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col, lower, regexp_replace, concat\n","from pyspark.ml.feature import (\n","    StringIndexer, RegexTokenizer, StopWordsRemover,\n","    HashingTF, IDF, Word2Vec, MinMaxScaler, NGram, CountVectorizer\n",")\n","\n","def limpar_texto(df: DataFrame, coluna=\"review\"):\n","    df = df.withColumn(coluna, regexp_replace(col(coluna), r\"<[^>]+>\", \"\"))     # remove tags simples\n","    df = df.withColumn(coluna, regexp_replace(col(coluna), r\"[^A-Za-z ]+\", \" \"))# só letras/espaço\n","    df = df.withColumn(coluna, regexp_replace(col(coluna), r\"\\s+\", \" \"))        # colapsa espaços\n","    df = df.withColumn(coluna, lower(col(coluna)))\n","    return df\n"],"metadata":{"id":"zvpyiFy5dnbI","executionInfo":{"status":"ok","timestamp":1762080487151,"user_tz":0,"elapsed":413,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Carregar CSV e etapas comuns (dropna, label, limpeza, tokens)\n","\n","# 1) Ler e manter apenas colunas usadas\n","reviews = spark.read.csv(csv_path, header=True, escape=\"\\\"\").select(\"sentiment\", \"review\")\n","\n","# 2) Remover nulos essenciais\n","reviews = reviews.na.drop(subset=[\"sentiment\", \"review\"])\n","\n","# 3) Label: sentiment -> label (pula valores inválidos sem travar)\n","indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\", handleInvalid=\"skip\")\n","df = indexer.fit(reviews).transform(reviews)\n","\n","# 4) Limpeza de texto + tokenização + stopwords\n","df = limpar_texto(df, coluna=\"review\")\n","df = RegexTokenizer(inputCol=\"review\", outputCol=\"words\", pattern=r\"\\W+\").transform(df)\n","df = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", caseSensitive=False).transform(df)\n"],"metadata":{"id":"2ANo8jB_dpPr","executionInfo":{"status":"ok","timestamp":1762080500150,"user_tz":0,"elapsed":12994,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Featurização HTF + TF-IDF\n","\n","# === HTF (unigramas com hashing) ===\n","htf = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=1<<18)  # opcional: 1<<18\n","htf_df = htf.transform(df)\n","HTFfeaturizedData = (\n","    htf_df.select(\"sentiment\", \"review\", \"label\", \"rawfeatures\")\n","          .withColumnRenamed(\"rawfeatures\", \"features\")\n",")\n","\n","# === TF-IDF (unigramas + bigramas com vocabulário) ===\n","# bigramas\n","ngram = NGram(n=2, inputCol=\"filtered\", outputCol=\"bigrams\")\n","df_ng = ngram.transform(df)\n","\n","# concatena unigrams + bigrams\n","df_tokens = df_ng.withColumn(\"tokens_12\", concat(\"filtered\", \"bigrams\"))\n","\n","# CountVectorizer com minDF=2 (similar ao sklearn)\n","cv = CountVectorizer(inputCol=\"tokens_12\", outputCol=\"rawfeatures\", minDF=2, vocabSize=1<<18)\n","cv_model = cv.fit(df_tokens)\n","cv_df = cv_model.transform(df_tokens)\n","\n","# IDF\n","idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n","idf_model = idf.fit(cv_df)\n","TFIDFfeaturizedData = idf_model.transform(cv_df) \\\n","    .select(\"sentiment\", \"review\", \"label\", \"features\")\n","\n"],"metadata":{"id":"lkaZFHIZdq7S","executionInfo":{"status":"ok","timestamp":1762080586906,"user_tz":0,"elapsed":86752,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Featurização Word2Vec (+ escala)\n","w2v = Word2Vec(inputCol=\"filtered\", outputCol=\"features\", vectorSize=250, minCount=5, seed=42)\n","w2v_df = w2v.fit(df).transform(df)\n","\n","scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n","scaled = scaler.fit(w2v_df).transform(w2v_df)\n","\n","W2VfeaturizedData = (\n","    scaled.select(\"sentiment\", \"review\", \"label\", \"scaledFeatures\")\n","          .withColumnRenamed(\"scaledFeatures\", \"features\")\n",")\n"],"metadata":{"id":"ag-8rQ1PduAH","executionInfo":{"status":"ok","timestamp":1762080774172,"user_tz":0,"elapsed":187264,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Salvar Parquet + retornar DFs (com nomes)\n","\n","# Salva no Drive\n","HTFfeaturizedData.write.mode(\"overwrite\").parquet(base_path + \"HTFfeaturizedData\")\n","TFIDFfeaturizedData.select(\"sentiment\",\"review\",\"label\",\"features\") \\\n","    .write.mode(\"overwrite\").parquet(base_path + \"TFIDFfeaturizedData\")\n","W2VfeaturizedData.write.mode(\"overwrite\").parquet(base_path + \"W2VfeaturizedData\")\n","\n","# Nomes amigáveis (usados depois no treinamento)\n","HTFfeaturizedData.name   = \"HTFfeaturizedData\"\n","TFIDFfeaturizedData.name = \"TFIDFfeaturizedData\"\n","W2VfeaturizedData.name   = \"W2VfeaturizedData\"\n","\n","print(\"Salvo em:\")\n","print(f\" - {base_path}HTFfeaturizedData\")\n","print(f\" - {base_path}TFIDFfeaturizedData\")\n","print(f\" - {base_path}W2VfeaturizedData\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sA6Q32UD_GyX","executionInfo":{"status":"ok","timestamp":1762080837371,"user_tz":0,"elapsed":63193,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"84dc7543-8f19-4a5d-a3ae-3b1f72c36a57"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Salvo em:\n"," - /content/drive/MyDrive/Eixo_05/dados/HTFfeaturizedData\n"," - /content/drive/MyDrive/Eixo_05/dados/TFIDFfeaturizedData\n"," - /content/drive/MyDrive/Eixo_05/dados/W2VfeaturizedData\n"]}]},{"cell_type":"code","source":["# Sanity check rápido\n","\n","print(\"Contagens:\",\n","      HTFfeaturizedData.count(),\n","      TFIDFfeaturizedData.count(),\n","      W2VfeaturizedData.count())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1bKm6DG_KIR","executionInfo":{"status":"ok","timestamp":1762080840409,"user_tz":0,"elapsed":3036,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"d8db2b63-bdb1-4bb9-d90e-58a45110792c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Contagens: 50000 50000 50000\n"]}]}]}