# Relat√≥rio de An√°lise de Resultados - Naive Bayes

**Data de Gera√ß√£o:** 18/11/2025 19:30:49

---

## üìä Resumo Executivo

Este relat√≥rio apresenta uma an√°lise completa dos resultados obtidos pelo modelo de Naive Bayes para an√°lise de sentimentos.

### Estat√≠sticas Gerais

- **Modelo Analisado:** TFIDF (5000 features)
- **Acur√°cia:** 85.95%
- **Taxa de Erro:** 14.05%

### Resultados Principais

| M√©trica | Valor | Interpreta√ß√£o |
|---------|-------|---------------|
| **Acur√°cia Geral** | 85.95% | O modelo acerta aproximadamente 86 de cada 100 classifica√ß√µes |
| **Precis√£o (Negative)** | 87% | Quando o modelo diz "negativo", est√° correto 87% das vezes |
| **Precis√£o (Positive)** | 85% | Quando o modelo diz "positivo", est√° correto 85% das vezes |
| **Recall (Negative)** | 84% | O modelo identifica 84% de todos os reviews negativos |
| **Recall (Positive)** | 87% | O modelo identifica 87% de todos os reviews positivos |
| **F1-Score** | 86% | Score geral de qualidade, balanceando precis√£o e recall |

### Conclus√µes Principais

1. ‚úÖ **Modelo bem-sucedido:** Acur√°cia de 85.95% √© um resultado s√≥lido para an√°lise de sentimentos
2. ‚úÖ **Desempenho equilibrado:** O modelo n√£o apresenta vi√©s significativo para nenhuma classe
3. ‚úÖ **Configura√ß√£o adequada:** TF-IDF com 5000 features oferece bom equil√≠brio performance/efici√™ncia

---

## üèÜ Melhor Modelo

**Configura√ß√£o:**
- M√©todo de Vetoriza√ß√£o: **TFIDF**
- N√∫mero de Features: **5000**
- Acur√°cia: **85.95%**
- Taxa de Erro: **14.05%**

---

## üìä Gr√°ficos e Visualiza√ß√µes

### 1. Compara√ß√£o de Acur√°cia

![Compara√ß√£o de Acur√°cia](graficos/comparacao_acuracia.png)

**Interpreta√ß√£o:** O modelo TFIDF (5000 features) alcan√ßou 85.95% de acur√°cia, indicando que acerta aproximadamente 86 de cada 100 classifica√ß√µes.

### 2. Matriz de Confus√£o

![Matriz de Confus√£o](graficos/matrizes_confusao.png)

**Interpreta√ß√£o:** 
- **Verdadeiros Negativos:** 4.224 (reviews negativos corretos)
- **Falsos Positivos:** 776 (negativos classificados como positivos)
- **Falsos Negativos:** 629 (positivos classificados como negativos)
- **Verdadeiros Positivos:** 4.371 (reviews positivos corretos)

A diagonal principal (azul escuro) mostra os acertos, indicando desempenho equilibrado.

### 3. Impacto do N√∫mero de Features

![Impacto do N√∫mero de Features](graficos/impacto_features.png)

**Interpreta√ß√£o:** 
- **Tend√™ncia:** Aumentar o n√∫mero de features geralmente melhora a acur√°cia
- **TF-IDF (verde):** Consistemente superior ao Count Vectorizer
- **Trade-off:** Mais features = melhor acur√°cia, mas tamb√©m = mais tempo de processamento
- **Ponto √≥timo:** 5000 features oferece bom equil√≠brio entre performance e efici√™ncia

### 4. Compara√ß√£o TF-IDF vs Count Vectorizer

![Compara√ß√£o TF-IDF vs Count Vectorizer](graficos/comparacao_metodos.png)

**Interpreta√ß√£o:**
- **TF-IDF (verde):** Supera Count Vectorizer em todas as configura√ß√µes
- **Diferen√ßa:** TF-IDF geralmente supera Count Vectorizer em 2-3 pontos percentuais
- **Conclus√£o:** TF-IDF √© o m√©todo mais adequado para este problema

---

## üìã Resultados Detalhados

### Matriz de Confus√£o

```
                    Predito
                 Negative  Positive
Real  Negative    4224      776
      Positive     629     4371
```

**An√°lise:**
- **Total de amostras testadas:** 10.000
- **Total de acertos:** 8.595 (85.95%)
- **Total de erros:** 1.405 (14.05%)
- O modelo √© ligeiramente melhor em identificar sentimentos positivos (4.371 vs 4.224)

### Relat√≥rio de Classifica√ß√£o

```
              precision    recall  f1-score   support

    negative       0.87      0.84      0.86      5000
    positive       0.85      0.87      0.86      5000

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
```

**M√©tricas por Classe:**

| Classe | Precision | Recall | F1-Score | Significado |
|--------|-----------|--------|----------|-------------|
| **Negative** | 87% | 84% | 86% | Quando diz "negativo", est√° correto 87% das vezes. Identifica 84% dos negativos. |
| **Positive** | 85% | 87% | 86% | Quando diz "positivo", est√° correto 85% das vezes. Identifica 87% dos positivos. |

---

## üí° Interpreta√ß√µes e Conclus√µes

### 1. M√©todo de Vetoriza√ß√£o

**TF-IDF** demonstrou ser superior porque:
- Pondera palavras por import√¢ncia (palavras comuns recebem menor peso)
- Reduz ru√≠do de palavras muito frequentes
- Melhor discrimina√ß√£o entre sentimentos positivos e negativos

### 2. N√∫mero de Features

**5000 features oferece:**
- ‚úÖ Performance: 85.95% de acur√°cia (satisfat√≥ria)
- ‚úÖ Efici√™ncia: Tempo de processamento razo√°vel
- ‚úÖ Uso de mem√≥ria: Consumo moderado

**Trade-off:** Aumentar para 10000 features pode melhorar apenas 1-2%, mas dobra o uso de recursos.

### 3. An√°lise do Desempenho

**Pontos Fortes:**
- ‚úÖ Acur√°cia de 85.95% (acerta 86 de cada 100)
- ‚úÖ Desempenho equilibrado entre classes
- ‚úÖ Precis√£o e recall consistentes (86% F1-Score)

**√Åreas de Melhoria:**
- ‚ö†Ô∏è 776 falsos positivos (15.5% dos negativos)
- ‚ö†Ô∏è 629 falsos negativos (12.6% dos positivos)
- ‚ö†Ô∏è Taxa de erro de 14.05% pode ser reduzida

### 4. Recomenda√ß√µes

**Para Produ√ß√£o:**
- ‚úÖ Utilizar o modelo TFIDF (5000 features) - Configura√ß√£o atual √© adequada
- ‚úÖ Monitorar performance em produ√ß√£o
- ‚úÖ Implementar sistema de feedback

**Para Melhorias:**
- üî¨ Testar diferentes n-grams e t√©cnicas de pr√©-processamento
- ‚öôÔ∏è Valida√ß√£o cruzada para sele√ß√£o de hiperpar√¢metros
- üöÄ Testar outros algoritmos (SVM, Random Forest) ou ensemble de modelos
- üîç Analisar features mais importantes e casos de erro

---

## üìÅ Arquivos Gerados

- `graficos/comparacao_acuracia.png` - Compara√ß√£o de acur√°cias entre modelos
- `graficos/matrizes_confusao.png` - Matriz de confus√£o do modelo
- `graficos/impacto_features.png` - Impacto do n√∫mero de features
- `graficos/comparacao_metodos.png` - Compara√ß√£o TF-IDF vs Count Vectorizer
- `metricas_detalhadas.csv` - Tabela com todas as m√©tricas calculadas

---

## üìù Notas Finais

### Contexto dos Resultados

**Compara√ß√£o com benchmarks:**
- Classificador aleat√≥rio: 50% de acur√°cia
- Modelo atual: **85.95% de acur√°cia**
- Modelos de ponta: 90-95% de acur√°cia

**Conclus√£o:** O modelo est√° **bem acima do acaso** e pr√≥ximo de resultados de ponta, sendo adequado para uso em produ√ß√£o.

### Aplicabilidade Pr√°tica

- ‚úÖ **Adequado para:** An√°lise geral de sentimentos, filtragem de reviews, an√°lise de tend√™ncias
- ‚ö†Ô∏è **Cuidado com:** Aplica√ß√µes cr√≠ticas onde cada erro tem alto custo
- üîç **Monitorar:** Performance em produ√ß√£o e ajustar conforme necess√°rio

### Pr√≥ximos Passos

1. **Curto Prazo:** An√°lise de erros e ajuste fino de par√¢metros
2. **M√©dio Prazo:** Testar outros algoritmos e valida√ß√£o cruzada
3. **Longo Prazo:** Ensemble de modelos ou Deep Learning (LSTM, BERT)

---

**Conclus√£o:** O modelo de Naive Bayes com TF-IDF e 5000 features demonstrou ser uma **solu√ß√£o eficaz e pr√°tica** para an√°lise de sentimentos, com 85.95% de acur√°cia e desempenho equilibrado, pronto para uso em produ√ß√£o.
